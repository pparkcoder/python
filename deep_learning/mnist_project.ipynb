{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e413fd5b",
   "metadata": {},
   "source": [
    "# 손글씨 data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18504d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55803cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0],cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0aeba1",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239fea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat = []\n",
    "for dat in x_train :\n",
    "    x_train_flat.append(list(dat.flatten()))\n",
    "x_train_flat = np.array(x_train_flat) / 255\n",
    "x_train_flat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153d202",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55172d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as ft\n",
    "y_enc = tf.keras.utils.to_categorical(y_train)\n",
    "y_enc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68aae7",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78906b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6053 - accuracy: 0.8292\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.9220\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.9333\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9398: 0s - loss: 0.2\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9430\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.9465: \n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.9494\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.9520\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1616 - accuracy: 0.9537\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9549\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9567\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9575\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9588\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9596\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1357 - accuracy: 0.9602\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9607\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1312 - accuracy: 0.9609\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9624\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1257 - accuracy: 0.9627\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1233 - accuracy: 0.9639\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1216 - accuracy: 0.9640\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9645\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1181 - accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1157 - accuracy: 0.9651\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.9661\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.9660\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9672\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.9675\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1080 - accuracy: 0.9681\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9683\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.9681\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9689\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.9696\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9690\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9702\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9706\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9702\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9706\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9708\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9711\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9715\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9719\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9723\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9728\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9725\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9726\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9730\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9733\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9738\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9739\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9744\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9739\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9746\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9750\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9750\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.9753\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9753\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9759\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9759\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9755\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9764\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9762\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9772\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9762\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9770\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9775\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0777 - accuracy: 0.9769\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9773\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9775\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9783\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9772\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9776\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9784\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9778\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9783\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0732 - accuracy: 0.9780\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0728 - accuracy: 0.9783\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.9782\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.9788\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0717 - accuracy: 0.9785\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0715 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.9790\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0700 - accuracy: 0.9790\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0691 - accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9791\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0687 - accuracy: 0.9799\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0680 - accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9798: 0s - loss: 0.066\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0678 - accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9804: 0s - loss: 0.0663 - accu\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9805\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9803\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9809\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9810\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0651 - accuracy: 0.9806\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.0577 - accuracy: 0.9834\n",
      "[0.05774886906147003, 0.9834166765213013]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16,input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax')) \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(x_train_flat,y_enc,epochs = 100, batch_size = 100) \n",
    "print(model.evaluate(x_train_flat,y_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b1c32",
   "metadata": {},
   "source": [
    "# 복잡도 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2072de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3463 - accuracy: 0.8948\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1023 - accuracy: 0.9708\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0735 - accuracy: 0.9787\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0533 - accuracy: 0.9841\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0435 - accuracy: 0.9868\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0341 - accuracy: 0.9894\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0284 - accuracy: 0.9912\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0272 - accuracy: 0.9917\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0236 - accuracy: 0.9928\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0178 - accuracy: 0.9946\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0157 - accuracy: 0.9951\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0120 - accuracy: 0.9964\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0065 - accuracy: 0.9983\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0077 - accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0066 - accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0067 - accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0067 - accuracy: 0.9983\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 9.6364e-04 - accuracy: 0.9998\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0052 - accuracy: 0.9988\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0070 - accuracy: 0.9985: 0s -\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0059 - accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 3.1504e-04 - accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.8985e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 5.8156e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 3.4254e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 2.0626e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.1960e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 6.5203e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 3.8840e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 2.2767e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.3989e-07 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 9.2878e-08 - accuracy: 1.0000: 0s - loss: 9.4171e-08 - accuracy\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 7.0605e-08 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 5.5138e-08 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 3.3411e-08 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 2.3612e-08 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 4s 7ms/step - loss: 1.5427e-08 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.0737e-08 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 7.8459e-09 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 5.8074e-09 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 4.3352e-09 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 3.1332e-09 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 2.3544e-09 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.7861e-09 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.3689e-09 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.0570e-09 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 8.3049e-10 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 6.4969e-10 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 5.0267e-10 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 3.9935e-10 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 3.2187e-10 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 2.5034e-10 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 1.8875e-10 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.5100e-10 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.2318e-10 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 1.0133e-10 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 9.1394e-11 - accuracy: 1.0000\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 8.1460e-11 - accuracy: 1.0000\n",
      "[8.14596654019617e-11, 1.0]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax')) #add를 추가할수록 히든레이어의 숫자는 작아져야 함\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(x_train_flat,y_enc,epochs = 100, batch_size = 100) \n",
    "print(model.evaluate(x_train_flat,y_enc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
